import pandas as pd
from lxml import etree

from openPM.Process.Instance import Instance
from openPM.Process.Activity import Activity
from openPM.Process.Attribute import Attribute

import timeit  # TODO remove after debugging


# TODO Build an Iterator!
class Process:
    counter = 0

    def __init__(self, path):
        # TODO-fixme I want to be a singelton!
        self.process = pd.DataFrame(columns=["instance_attributes", "event_attributes"])
        self.instance_id = 1
        self.__parse_xes(path)

    def __parse_xes(self, path: str):
        print("STATISTICS:  ", file=open("evaluate_1.txt", "a"))
        start1 = timeit.default_timer()
        for _, trace in etree.iterparse(path, tag='trace'):
            instance = Instance()
            for event in trace.iterchildren("event"):
                act = Activity()
                for attribute in event.iterchildren():
                    pass
                    atr = Attribute(attribute.attrib["key"], attribute.attrib["value"])
                    act.add_attribute(atr)
                instance.add_activity(act)
            self.add_process_instance(instance)
        stop1 = timeit.default_timer()
        print(
            " Time to parse only objects instantiation and act.add_attribute(), "
            "inst.add_activity [s], add_process_instance():  ",
            stop1 - start1, file=open("evaluate_1.txt", "a"))

    def __iter__(self):
        return self

    # TODO-fixme it seems that the iterator doesn't consider order of isntances in event log
    # TODO-note Using the iterator is now faster, but still not the fastest way to do it because of the df.append()function.
    def __next__(self):
        process = self.process
        index_array = process.index.values
        max_index = max(index_array)
        for _ in index_array:
            if self.counter >= max_index:
                self.counter = 0
                raise StopIteration
            else:
                self.counter += 1
                instance = self.process.iloc[self.counter]
                events = instance["event_attributes"]

                instance_dicts = []
                for event in events:
                    attributes = event.get_attributes()
                    dicts = {}
                    for attribute in attributes:
                        dicts[attribute.get_key()] = attribute.get_value()
                    instance_dicts.append(dicts)

                df = pd.DataFrame(instance_dicts)
                return df

    def add_process_instance(self, instance: Instance):
        attributes = instance.get_attributes()

        events = instance.get_activities()

        index = len(self.process)  # last index of self.process
        # TODO make notes!
        self.process.at[index, "instance_attributes"] = attributes
        self.process.at[index, "event_attributes"] = events

    # TODO-fixme Needs to be rewriten because datastructure changed!
    # TODO Type hinting pandas.series?
    def get_all_activities(self):
        activities = self.process.loc[:, "event_attributes"]  # returns series. Unique kills duplicates
        return activities

    def get_start_activities(self, activity_column: str) -> set:
        start_activities = set()
        for instance in self:
            start_activities.add(instance.loc[0, activity_column])
        return start_activities

    def get_end_activities(self, activity_column: str):
        end_activities = set()
        for instance in self:
            end_activities.add(instance.iloc[-1][activity_column])
        return end_activities

    def get_process(self):
        return self.process

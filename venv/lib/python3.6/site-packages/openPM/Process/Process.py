import pandas as pd
from lxml import etree

from openPM.Process.Instance import Instance
from openPM.Process.Activity import Activity
from openPM.Process.Attribute import Attribute

import timeit  # Todo  remove after debugging


class Process:
    """
    This class represents a complete Process consisting of  multiple process instances (Instance), activitities
    and attributes.

    Parameters
    -----------

    path :
        the path to a valide process document. Valid process documents are in the moment XES documents.

    """
    counter = 0

    def __init__(self, path):

        self.process = pd.DataFrame(columns=["instance_attributes", "event_attributes"])
        self.instance_id = 1
        self.__parse_xes(path)

    def __repr__(self):
        return self.process.to_string()

    def __parse_xes(self, path: str) -> None:
        """
        The method parses a XES document into an process object. First instances and activities of
        the process a created by parsing the DOM-Elements <trace> and <event>. Aftwawds the attributes
        for the activity are parsed and added to an activity ,from all child elements of the
        <event> tag.

        :param path: path to valid process document.
        :return: None
        """
        print("STATISTICS:  ", file=open("evaluate_1.txt", "a"))
        start1 = timeit.default_timer()
        for _, trace in etree.iterparse(path, tag='trace'):
            instance = Instance()
            for event in trace.iterchildren("event"):
                act = Activity()
                for attribute in event.iterchildren():
                    pass
                    atr = Attribute(attribute.attrib["key"], attribute.attrib["value"])
                    act.add_attribute(atr)
                instance.add_activity(act)
            self.add_process_instance(instance)
        stop1 = timeit.default_timer()
        print(
            " Time to parse only objects instantiation and act.add_attribute(), "
            "inst.add_activity [s], add_process_instance():  ",
            stop1 - start1, file=open("evaluate_1.txt", "a"))

    def __iter__(self):
        return self

    # TODO-fixme it seems that the iterator doesn't consider order of isntances in event log
    # TODO-note Using the iterator is now faster,
    # but still not the fastest way to do it because of the df.append() function.
    def __next__(self):
        process = self.process
        index_array = process.index.values
        max_index = max(index_array)
        for _ in index_array:
            if self.counter >= max_index:
                self.counter = 0
                raise StopIteration
            else:
                self.counter += 1
                instance = self.process.iloc[self.counter]
                events = instance["event_attributes"]

                instance_dicts = []
                for event in events:
                    attributes = event.attributes
                    dicts = {}
                    for attribute in attributes:
                        dicts[attribute.key] = attribute.value
                    instance_dicts.append(dicts)

                df = pd.DataFrame(instance_dicts)
                return df

    def add_process_instance(self, instance: Instance) -> None:
        """
        Adds a instance object to the process.

        :param instance: Instance object
        :return: None
        """
        attributes = instance.attributes
        events = instance.activities
        index = len(self.process)  # last index of self.process

        self.process.at[index, "instance_attributes"] = attributes
        self.process.at[index, "event_attributes"] = events

    def get_all_activities(self, unique=False) -> pd.Series:
        """
        :param unique: If returned pd.Series contains duplicates or not.
        :return:  pd.Series with all activities of the process
        """
        activities = self.process.loc[:, "event_attributes"]# returns series. Unique kills duplicates
        if unique is True:
            activties = activities.unique()
        return activities

    # TODO are they still working?????
    def get_start_activities(self, activity_column: str) -> set:
        """
        Returns all start activities of the process according to the specified activity column.
        :param activity_column: The column which contains the activities
        :return: None
        """
        start_activities = set()
        for instance in self:
            start_activities.add(instance.loc[0, activity_column])
        return start_activities


    def get_end_activities(self, activity_column: str):
        end_activities = set()
        for instance in self:
            end_activities.add(instance.iloc[-1][activity_column])
        return end_activities


    @staticmethod
    def flat_process(process):
        instances = [instance for instance in process]
        df = pd.concat([instance for instance in instances], ignore_index=True)
        return df
